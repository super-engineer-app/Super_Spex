glasses button must load the glasses activity and show the projected ui on the glasses

Next steps: Native app polish
- Test full connect → project → dashboard flow on real device / emulator
- Verify speech recognition works end-to-end (glasses mic → text on phone)
- Verify camera capture from glasses (ProjectedContext) works in all modes
- Test Remote View streaming from native (Agora push frames → web viewer)
- Test video recording + transcription pipeline (record → stop → transcribe)
- Test tagging flow (voice trigger → capture images → save with GPS)
- Test parking timer (start → warning at 5 min left → expiry)
- Check demo mode (phone camera/mic fallback when no glasses connected)
- Check process separation is stable (no UI corruption after XR permission overlay)
- Verify keep-screen-on during streaming and recording
- Check error handling: no glasses connected, camera denied, mic denied, network down
- Run Kotlin linters: cd android && ./gradlew ktlintCheck detekt
- Run TypeScript check: npx tsc --noEmit
- Test release APK build: cd android && ./gradlew assembleRelease